{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License\n",
    "\n",
    "    Jupyter notebook for computing Pi using Monte Carlo sampling\n",
    "    Copyright (C) 2018 Andre.Brodtkorb@ifi.uio.no\n",
    "\n",
    "    This program is free software: you can redistribute it and/or modify\n",
    "    it under the terms of the GNU General Public License as published by\n",
    "    the Free Software Foundation, either version 3 of the License, or\n",
    "    (at your option) any later version.\n",
    "\n",
    "    This program is distributed in the hope that it will be useful,\n",
    "    but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "    GNU General Public License for more details.\n",
    "\n",
    "    You should have received a copy of the GNU General Public License\n",
    "    along with this program.  If not, see <http://www.gnu.org/licenses/>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets have matplotlib \"inline\"\n",
    "%matplotlib inline\n",
    "\n",
    "#Import packages we need\n",
    "import numpy as np\n",
    "import pycuda.compiler as cuda_compiler\n",
    "from pycuda.gpuarray import GPUArray\n",
    "import pycuda.driver as cuda_driver\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import IPythonMagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cuda_context_handler context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_kernel = \"\"\"\n",
    "//Based on Stroustrup, adapted for CUDA\n",
    "__device__ float generateRandomNumber(long& last_draw) {\n",
    "    last_draw = last_draw*1103515245 + 12345;\n",
    "    long abs = last_draw & 0x7fffffff;\n",
    "    return abs / 2147483648.0; \n",
    "}\n",
    "\n",
    "\n",
    "/**\n",
    "  * @param output Where to place results\n",
    "  * @param seed Seed used to seed the RNG (Linear congruential generator)\n",
    "  * Uses only for 1 thread per block\n",
    "  */\n",
    "__global__ void generateRandomNumbers(unsigned int* output, unsigned int seed) {\n",
    "    unsigned int tid = blockIdx.x;\n",
    "    long spacing = 18446744073709551615ul / static_cast<unsigned long>(gridDim.x);\n",
    "    long last_draw = seed + tid*spacing; //Initialize the LCG to seed, and keep track of last drawn long\n",
    "    \n",
    "    //Generate coordinate\n",
    "    output[tid] = int(generateRandomNumber(last_draw) + 0.5f);\n",
    "}\n",
    "\n",
    "\n",
    "/**\n",
    "  * @param output Where to place results\n",
    "  * @param seed Seed used to seed the RNG (Linear congruential generator)\n",
    "  * Uses only for 1 thread per block\n",
    "  */\n",
    "__global__ void computePi1(unsigned int* output, unsigned int seed) {\n",
    "    //You need to implement this kernel!\n",
    "//    unsigned int tid = blockIdx.x;\n",
    "    unsigned int tid = blockIdx.x*blockDim.x + threadIdx.x;\n",
    "    long spacing = 18446744073709551615ul / static_cast<unsigned long>(gridDim.x);\n",
    "    long last_draw = seed + tid*spacing; //Initialize the LCG to seed, and keep track of last drawn long\n",
    "    \n",
    "    //Generate coordinate\n",
    "    float x = generateRandomNumber(last_draw);\n",
    "    float y = generateRandomNumber(last_draw);\n",
    "    float r = sqrt(x*x + y*y);\n",
    "    \n",
    "    if (r < 1.0f) {\n",
    "        output[tid] = 1;\n",
    "    } else {\n",
    "        output[tid] = 0;    \n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "__global__ void computePi3(unsigned int* output, unsigned int seed) {\n",
    "    __shared__ int inside[32];\n",
    "    unsigned int tid = blockIdx.x*blockDim.x + threadIdx.x;\n",
    "    \n",
    "    \n",
    "    long spacing = 18446744073709551615ul / static_cast<unsigned long>(gridDim.x);\n",
    "    long last_draw = seed + tid*spacing; //Initialize the LCG to seed, and keep track of last drawn long\n",
    "    \n",
    "    //Generate coordinate\n",
    "    float x = generateRandomNumber(last_draw);\n",
    "    float y = generateRandomNumber(last_draw);\n",
    "    float r = sqrt(x*x + y*y);\n",
    "    \n",
    "    if (r <= 1.0f) {\n",
    "        inside[threadIdx.x] = 1;\n",
    "    } else {\n",
    "        inside[threadIdx.x] = 0;\n",
    "    }    \n",
    "    __syncthreads();\n",
    "    \n",
    "    volatile int* p = inside;\n",
    "    if (threadIdx.x < 16) {\n",
    "        p[threadIdx.x] = p[threadIdx.x] + p[threadIdx.x+16];\n",
    "    __syncthreads();\n",
    "        p[threadIdx.x] = p[threadIdx.x] + p[threadIdx.x+8];\n",
    "    __syncthreads();\n",
    "        p[threadIdx.x] = p[threadIdx.x] + p[threadIdx.x+4];\n",
    "    __syncthreads();\n",
    "        p[threadIdx.x] = p[threadIdx.x] + p[threadIdx.x+2];\n",
    "    __syncthreads();\n",
    "        p[threadIdx.x] = p[threadIdx.x] + p[threadIdx.x+1];\n",
    "    }\n",
    "    if (threadIdx.x == 0) {\n",
    "        output[blockIdx.x] = p[0];\n",
    "//        output[blockIdx.x] = inside[threadIdx.x];\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "module = cuda_compiler.SourceModule(cuda_kernel);\n",
    "randomNumbers = module.get_function(\"generateRandomNumbers\");\n",
    "computePi1 = module.get_function(\"computePi1\");\n",
    "computePi3 = module.get_function(\"computePi3\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pi computed on the CPU is 3.14676\n"
     ]
    }
   ],
   "source": [
    "def computePiCPU(n_points):\n",
    "    n_inside = 0\n",
    "    for i in range(n_points):\n",
    "        x = np.random.rand()\n",
    "        y = np.random.rand()\n",
    "        r = np.sqrt(x*x + y*y)\n",
    "        if (r < 1.0):\n",
    "            n_inside += 1\n",
    "            \n",
    "    return 4*n_inside/n_points\n",
    "\n",
    "print(\"Pi computed on the CPU is \" + str(computePiCPU(100000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pi computed on the GPU is 3.14159324\n"
     ]
    }
   ],
   "source": [
    "def computePi1GPU(n_points):\n",
    "    #Set block and grid size\n",
    "#    block = (1, 1, 1)\n",
    "#    grid = (n_points, 1, 1)\n",
    "    block = (32, 1, 1)\n",
    "    grid = (n_points//32, 1, 1)\n",
    "    \n",
    "    #Allocate the output data on the GPU and on the CPU\n",
    "    output = np.empty((n_points, 1), dtype=np.uint32)\n",
    "    output_gpu = GPUArray(output.shape, np.uint32)\n",
    "\n",
    "    #Execute program on device\n",
    "    computePi3(output_gpu.gpudata, np.uint32(0), block=block, grid=grid)\n",
    "\n",
    "    #Copy data from device to host\n",
    "    output_gpu.get(output)\n",
    "    pi = 4*np.sum(output)/n_points\n",
    "    return pi\n",
    "    \n",
    "#    print(\"Pi is \" + str(4*np.sum(output)/n_points) )\n",
    "\n",
    "#    return 0.0\n",
    "\n",
    "print(\"Pi computed on the GPU is \" + str(computePi1GPU(100000000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
